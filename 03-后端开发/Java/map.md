在 Java 中，`Map` 是一个接口，常见的实现类包括 `HashMap`、`LinkedHashMap`、`TreeMap` 等。每种实现的操作复杂度不同。下面我会列出这些常见 `Map` 实现类的操作及其对应的时间复杂度。

### 1. `**HashMap**`
`HashMap` 是基于哈希表的实现，提供了 O(1) 的查找、插入和删除操作。它不保证元素的顺序，但提供了很高的性能。

#### 时间复杂度：
+ `**put(key, value)**`: 平均 O(1)，最坏 O(n)（当哈希冲突非常多时，所有元素都在同一个桶中，退化为链表或树结构）。
+ `**get(key)**`: 平均 O(1)，最坏 O(n)。
+ `**remove(key)**`: 平均 O(1)，最坏 O(n)。
+ `**containsKey(key)**`: 平均 O(1)，最坏 O(n)。
+ `**containsValue(value)**`: O(n)（需要遍历所有值）。
+ `**size()**`: O(1)。
+ `**isEmpty()**`: O(1)。
+ `**clear()**`: O(n)（清空所有元素）。

#### 特点：
+ 使用哈希函数快速查找元素。
+ 如果发生哈希冲突，`HashMap` 会使用链表或红黑树来解决冲突（Java 8+）。

---

### 2. `**LinkedHashMap**`
`LinkedHashMap` 继承自 `HashMap`，并在其基础上维护了一个双向链表，用来保证元素的插入顺序或访问顺序。

#### 时间复杂度：
+ `**put(key, value)**`: 平均 O(1)，最坏 O(n)。
+ `**get(key)**`: 平均 O(1)，最坏 O(n)。
+ `**remove(key)**`: 平均 O(1)，最坏 O(n)。
+ `**containsKey(key)**`: 平均 O(1)，最坏 O(n)。
+ `**containsValue(value)**`: O(n)（需要遍历所有值）。
+ `**size()**`: O(1)。
+ `**isEmpty()**`: O(1)。
+ `**clear()**`: O(n)。
+ `**entrySet()**`: O(n)（按插入顺序或访问顺序返回键值对）。

#### 特点：
+ 保持插入顺序或访问顺序，适用于需要维持顺序的应用。
+ 性能与 `HashMap` 类似，但会额外维护一个双向链表，因此比 `HashMap` 稍微慢一些。

---

### 3. `**TreeMap**`
`TreeMap` 是基于红黑树的实现，提供按自然顺序或自定义比较器排序的键值对。

#### 时间复杂度：
+ `**put(key, value)**`: O(log n)（红黑树的插入操作）。
+ `**get(key)**`: O(log n)（红黑树的查找操作）。
+ `**remove(key)**`: O(log n)（红黑树的删除操作）。
+ `**containsKey(key)**`: O(log n)（红黑树的查找操作）。
+ `**containsValue(value)**`: O(n)（需要遍历所有值）。
+ `**size()**`: O(1)。
+ `**isEmpty()**`: O(1)。
+ `**clear()**`: O(n)（清空树中的所有节点）。

#### 特点：
+ `TreeMap` 保证键的有序性（按自然顺序或自定义比较器排序），因此插入、查找和删除操作的时间复杂度为 O(log n)。
+ `TreeMap` 比 `HashMap` 和 `LinkedHashMap` 慢，因为它需要维护一个有序的红黑树。

---

### 4. `**ConcurrentHashMap**`
`ConcurrentHashMap` 是线程安全的 `Map` 实现，适用于多线程并发访问的场景。它通过分段锁来提高并发性能。

#### 时间复杂度：
+ `**put(key, value)**`: 平均 O(1)，最坏 O(n)（取决于哈希冲突和锁的粒度）。
+ `**get(key)**`: 平均 O(1)，最坏 O(n)。
+ `**remove(key)**`: 平均 O(1)，最坏 O(n)。
+ `**containsKey(key)**`: 平均 O(1)，最坏 O(n)。
+ `**containsValue(value)**`: O(n)（需要遍历所有值）。
+ `**size()**`: O(1)。
+ `**isEmpty()**`: O(1)。
+ `**clear()**`: O(n)（清空所有元素）。

#### 特点：
+ 线程安全，适用于高并发环境。
+ 相比于 `Hashtable`，`ConcurrentHashMap` 提供了更高的并发性能。
+ 与 `HashMap` 相比，`ConcurrentHashMap` 在性能上可能略有下降，因为它需要同步操作。

---

### 5. `**WeakHashMap**`
`WeakHashMap` 是一种特殊的 `Map` 实现，它使用 **弱引用**（Weak Reference）来保存键对象。这意味着当一个键对象没有强引用时，它会被垃圾回收器回收。

#### 时间复杂度：
+ `**put(key, value)**`: O(1)。
+ `**get(key)**`: O(1)。
+ `**remove(key)**`: O(1)。
+ `**containsKey(key)**`: O(1)。
+ `**containsValue(value)**`: O(n)（需要遍历所有值）。
+ `**size()**`: O(1)。
+ `**isEmpty()**`: O(1)。
+ `**clear()**`: O(n)。

#### 特点：
+ `WeakHashMap` 中的键使用弱引用，因此如果一个键不再被引用，它会被垃圾回收器自动删除。
+ 适用于缓存场景，避免因为强引用而导致内存泄漏。

---

### **总结：**
| **操作** | `**HashMap**` | `**LinkedHashMap**` | `**TreeMap**` | `**ConcurrentHashMap**` | `**WeakHashMap**` |
| --- | --- | --- | --- | --- | --- |
| `**put(key, value)**` | O(1) | O(1) | O(log n) | O(1) | O(1) |
| `**get(key)**` | O(1) | O(1) | O(log n) | O(1) | O(1) |
| `**remove(key)**` | O(1) | O(1) | O(log n) | O(1) | O(1) |
| `**containsKey(key)**` | O(1) | O(1) | O(log n) | O(1) | O(1) |
| `**containsValue(value)**` | O(n) | O(n) | O(n) | O(n) | O(n) |
| `**size()**` | O(1) | O(1) | O(1) | O(1) | O(1) |
| `**isEmpty()**` | O(1) | O(1) | O(1) | O(1) | O(1) |
| `**clear()**` | O(n) | O(n) | O(n) | O(n) | O(n) |


### **总结说明：**
+ `**HashMap**` 和 `**LinkedHashMap**` 提供了常数时间的查找和插入操作，但它们不保证元素顺序，`LinkedHashMap` 可以保证顺序（插入顺序或访问顺序）。
+ `**TreeMap**` 的查找、插入和删除操作是 O(log n)，并且保持元素的有序性。
+ `**ConcurrentHashMap**` 提供线程安全的操作，适合多线程环境，但可能略微牺牲性能。
+ `**WeakHashMap**` 使用弱引用来管理键对象，在内存压力大的时候能自动回收无强引用的键对象。

根据不同的使用场景，可以选择合适的 `Map` 实现。



# hashmap 中的那段话
是的，这段话与 **链表转为红黑树** 有关，具体来说，它描述了 `ConcurrentHashMap` 在 **JDK 1.8** 中如何使用 **红黑树（TreeNode）** 来优化哈希桶中元素的存储结构，特别是在链表长度超过某个阈值时。

下面是对这段话的详细解释：

### 1. **TreeNode 比普通节点大约大两倍**
这句话的意思是，红黑树节点（`TreeNode`）比链表节点（`Node`）要大得多。在 `ConcurrentHashMap` 中，链表节点是存储哈希冲突元素的基本单元，而红黑树节点是更复杂的数据结构，需要额外的存储空间。由于红黑树的结构比链表复杂，它们的内存开销较大，因此只有当桶中的元素足够多时才会转换成红黑树，以确保性能优化是值得的。

### 2. **TreeNode 只在桶中节点足够多时使用（见 **`**TREEIFY_THRESHOLD**`**）**
`TREEIFY_THRESHOLD` 是一个常量，它定义了桶中的节点数量阈值，当某个桶中元素的数量超过该阈值时，链表会被转化为红黑树。这个阈值通常设置为 **8**，即如果某个桶中的元素超过 8 个，就会考虑将链表转换为红黑树。如果桶中的元素少于这个阈值，即使发生了哈希冲突，链表也继续存在，因为链表结构在小规模数据下更加节省内存和简单高效。

### 3. **当桶中节点变得过少时，会将红黑树转回普通链表（由于删除或调整大小）**
当 `ConcurrentHashMap` 进行扩容（resize）或者删除元素后，桶中的元素数量可能会减少。如果一个桶中原本使用红黑树存储，而树的节点数量减少到某个阈值以下（通常是 6 或更少），该桶会重新转换回链表。这是为了减少内存开销，因为红黑树的存储开销比链表要大。

### 4. **在哈希码分布良好的情况下，树桶很少使用**
如果用户的哈希码分布良好，即哈希冲突少，那么 `ConcurrentHashMap` 会尽量避免使用红黑树。因为好的哈希分布能确保大部分桶中的元素很少或没有冲突，链表长度短，甚至为空。这时，链表足以存储这些元素，红黑树的复杂度反而成为负担。

### 5. **随机哈希码下，桶中节点的频率遵循 Poisson 分布**
假设哈希码是随机的，`ConcurrentHashMap` 中每个桶的元素数量遵循 **Poisson 分布**，即每个桶中的元素数量随着桶的数量增加，出现大量元素的概率会下降。Poisson 分布的参数为 **0.5**，表示平均每个桶中大约会有 0.5 个元素。根据这个分布，`ConcurrentHashMap` 理论上只会在极少数情况下使用红黑树。

### 6. **元素数量较大时，链表长度与 Poisson 分布中的概率相关**
这部分提到，随着桶中节点数量增加，链表的长度符合 Poisson 分布的期望值。例如，长度为 0 的桶出现的概率大约是 **0.6065**，长度为 1 的桶的概率是 **0.3033**，长度为 2 的桶的概率是 **0.0758**，以此类推。这样，只有在哈希冲突极为严重的情况下，链表长度才会非常长，导致考虑转换为红黑树。

### 总结
这段话描述了在 **JDK 1.8** 中，`ConcurrentHashMap` 如何通过使用红黑树（TreeNode）来优化哈希桶中元素存储结构的转换过程。当桶中的元素超过 `TREEIFY_THRESHOLD`（通常为 8）时，链表会被转换为红黑树，以提高查询效率。如果桶中节点减少到一定程度（例如通过删除操作或扩容导致），红黑树会再次转换回链表。哈希冲突的数量和元素的分布决定了是否会使用红黑树，而良好的哈希分布通常避免了红黑树的使用，从而减少了内存开销和复杂度。

### 是否与链表转为红黑树有关？
是的，这段话主要讨论了当桶中链表的长度超过某个阈值时，`ConcurrentHashMap` 如何将链表转化为红黑树（树化）。同时，它还提到在内存开销较大时，如何将红黑树转换回链表，以平衡性能和空间效率。

在 `ConcurrentHashMap` 中，提到每个桶的元素数量遵循 **Poisson 分布**，这个说法是基于一个假设——**哈希码是随机且均匀分布的**。Poisson 分布是用于描述 **稀疏事件发生次数**的概率分布，当哈希冲突在某个桶中是随机且均匀的情况下，桶中元素的数量大致符合这种分布。

让我们从多个角度深入分析这个问题：

### 1. **Poisson 分布的简介**
Poisson 分布通常用于描述单位时间或单位空间内稀疏事件发生的次数，且这些事件是 **独立** 的，且 **均匀** 地分布。例如，某个桶中的元素数量通常是由以下因素决定的：

+ **哈希函数的质量**：假设哈希函数将所有元素均匀地映射到桶中，避免了元素聚集到某些桶，而导致哈希冲突。
+ **冲突的独立性**：即每次哈希冲突的发生是独立的。

Poisson 分布的概率质量函数（PMF）为：

P(k)=λke−λk!P(k) = \frac{\lambda^k e^{-\lambda}}{k!}

其中：

+ λ\lambda 是期望值（即平均发生的事件次数，通常是桶中的平均元素数）。
+ kk 是桶中元素的数量。
+ ee 是自然常数。

### 2. **为什么桶中的元素数量符合 Poisson 分布**
假设有 NN 个元素被散列到 `ConcurrentHashMap` 中，`ConcurrentHashMap` 中的桶数量为 MM。每个元素的哈希值是独立且均匀分布的。对于每个桶，哈希冲突的发生是随机且独立的，且每个桶接收到元素的数量是独立的。

在这样的条件下，哈希冲突的发生次数就可以看作是一个 **稀疏随机过程**。根据 **Poisson 分布** 的特性，如果每个桶中的哈希冲突是独立且均匀分布的，桶中的元素数量就大致符合 Poisson 分布。

具体地，**Poisson 分布** 被用来描述桶中元素数量的原因是：

+ 在大规模数据集中，哈希冲突不会集中在少数几个桶，而是会均匀分布到所有桶中。
+ 每个桶的哈希冲突事件发生的概率与其他桶无关，即这些冲突是独立的。
+ 因为冲突发生的次数是独立且随机的，这些冲突符合 Poisson 分布的特征。

### 3. **如何推导 Poisson 分布**
假设每个桶中的元素数量服从某种概率分布，并且在足够大的哈希表中，元素会在各个桶之间均匀分布。我们可以得到每个桶中元素的期望数量 λ\lambda，这个期望值大约为总元素数 NN 除以桶的数量 MM，即 λ=NM\lambda = \frac{N}{M}。

由于 **Poisson 分布** 描述的是 **稀疏独立事件的发生次数**，因此在每个桶中的元素数量在大量数据情况下遵循 Poisson 分布。

### 4. **Poisson 分布的实际意义**
在实际应用中，Poisson 分布能准确地预测某个桶中元素数量的概率。例如，假设期望每个桶中平均有 0.50.5 个元素（即 λ=0.5\lambda = 0.5），根据 Poisson 分布，可以计算出：

+ 桶中没有元素的概率：P(0)=e−0.5≈0.6065P(0) = e^{-0.5} \approx 0.6065
+ 桶中有 1 个元素的概率：P(1)=0.3033P(1) = 0.3033
+ 桶中有 2 个元素的概率：P(2)=0.0758P(2) = 0.0758

这种概率分布表明，绝大部分桶会有 0 或 1 个元素，随着桶中元素数量的增多，出现更多元素的概率急剧下降。这符合哈希函数的理想情况——大部分桶为空或仅包含少量元素，极少数桶包含大量元素。

### 5. **为什么说每个桶的元素数量符合 Poisson 分布**
这个说法的核心是 **均匀分布** 和 **独立性**。如果哈希函数将元素均匀地分布到桶中，每个元素的哈希值与其他元素的哈希值独立，且没有任何偏倚，那么桶中元素的数量会遵循 **Poisson 分布**。

+ **均匀分布**：哈希值均匀分布的情况下，不同桶中出现大量元素的概率较小，导致大多数桶中元素数量较少。
+ **独立性**：每个元素的哈希冲突是独立的，即一个元素是否映射到某个桶不依赖于其他元素的映射。

因此，**Poisson 分布** 描述了这些元素的分布情况，并且在大多数情况下是合适的。

### 6. **实际效果**
+ **哈希冲突少**：Poisson 分布意味着大多数桶中的元素数量是比较小的，极少数桶中元素数量较多，这有助于避免哈希冲突集中到少数几个桶中，导致性能瓶颈。
+ **低冲突的性能**：这种分布使得 `ConcurrentHashMap` 能在没有过多冲突的情况下高效地工作，避免了链表过长或者红黑树转换的情况。

### 总结
桶中元素数量遵循 **Poisson 分布** 的原因是，`ConcurrentHashMap` 假设哈希函数能够将元素均匀且独立地分配到各个桶中，从而使得每个桶中的哈希冲突是 **独立且稀疏的**。由于这些条件符合 Poisson 分布的特性，桶中元素数量的分布大致符合 Poisson 分布，从而能高效地预测和处理桶中元素的数量。这种设计能够确保哈希表在高并发环境下具有较好的性能和低冲突概率。





